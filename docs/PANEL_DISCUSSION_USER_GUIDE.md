<p align="center">
  <img src="../src/CopilotAgent.App/Resources/app.png" alt="CopilotDesktop Logo" width="80" />
</p>

<h1 align="center">Panel Discussion â€” User Guide</h1>

<p align="center">
  <strong>CopilotDesktop v2.0</strong> Â· Multi-Expert AI Debate System for Deep Analysis<br/>
  <em>Assemble a panel of AI experts â€” each with unique expertise and personality â€” to analyze, debate, and synthesize insights on any topic you bring to the table.</em>
</p>

---

## Table of Contents

1. [What is Panel Discussion?](#1-what-is-panel-discussion)
2. [Why Use a Panel? â€” Value Proposition](#2-why-use-a-panel--value-proposition)
3. [Quick Start â€” Your First Panel in 2 Minutes](#3-quick-start--your-first-panel-in-2-minutes)
4. [Understanding the Interface](#4-understanding-the-interface)
   - 4.1 [Three-Pane Layout Overview](#41-three-pane-layout-overview)
   - 4.2 [Header Bar â€” Your Command Center](#42-header-bar--your-command-center)
   - 4.3 [Execution Bar â€” Live Pulse](#43-execution-bar--live-pulse)
   - 4.4 [Left Pane â€” Head Agent Chat](#44-left-pane--head-agent-chat)
   - 4.5 [Center Pane â€” Discussion Stream](#45-center-pane--discussion-stream)
   - 4.6 [Right Pane â€” Agent Inspector](#46-right-pane--agent-inspector)
   - 4.7 [Bottom Input Bar](#47-bottom-input-bar)
   - 4.8 [Side Panel â€” Settings & Event Log](#48-side-panel--settings--event-log)
   - 4.9 [Synthesis Report Overlay](#49-synthesis-report-overlay)
5. [The Discussion Lifecycle â€” From Topic to Synthesis](#5-the-discussion-lifecycle--from-topic-to-synthesis)
6. [Discussion Depth â€” Controlling Analysis Intensity](#6-discussion-depth--controlling-analysis-intensity)
7. [Commentary Mode â€” Controlling Verbosity](#7-commentary-mode--controlling-verbosity)
8. [Meet the Panelists â€” Default Expert Profiles](#8-meet-the-panelists--default-expert-profiles)
9. [Preset Panels â€” Ready-Made Expert Teams](#9-preset-panels--ready-made-expert-teams)
10. [Convergence â€” How Consensus Emerges](#10-convergence--how-consensus-emerges)
11. [Guard Rails â€” Safety & Resource Limits](#11-guard-rails--safety--resource-limits)
12. [Settings Reference](#12-settings-reference)
13. [Phase Reference](#13-phase-reference)
14. [Agent Role Reference](#14-agent-role-reference)
15. [Worked Example â€” Architecture Review](#15-worked-example--architecture-review)
16. [Worked Example â€” Security Audit](#16-worked-example--security-audit)
17. [Worked Example â€” Deep Research Question](#17-worked-example--deep-research-question)
18. [Best Practices & Tips](#18-best-practices--tips)
19. [How Panel Discussion Differs from Agent Team & Agent Office](#19-how-panel-discussion-differs-from-agent-team--agent-office)
20. [Troubleshooting](#20-troubleshooting)
21. [Glossary](#21-glossary)
22. [Frequently Asked Questions](#22-frequently-asked-questions)
23. [Appendix â€” Keyboard Shortcuts](#23-appendix--keyboard-shortcuts)

---

## 1. What is Panel Discussion?

**Panel Discussion** is a structured multi-expert AI debate system built into CopilotDesktop. You pose a topic or question, and a team of AI panelists â€” each with distinct expertise, personality, and analysis style â€” engages in a moderated discussion to produce a comprehensive synthesis.

It's like convening a panel of senior engineers, architects, and specialists in a conference room. Each expert examines your topic through their unique lens (security, performance, architecture, UX, QA, DevOps), challenges each other's positions, and ultimately converges on actionable, multi-perspective insights.

### The Cast of Characters

| Agent | Role | What They Do |
|---|---|---|
| ðŸŽ“ **Head Agent** | Discussion Director | Your personal interface. Clarifies your topic, builds a discussion plan, selects panelists, initiates debate, and delivers the final synthesis. |
| ðŸ›¡ï¸ **Moderator** | Quality Guardian | Works behind the scenes. Enforces guard rails, detects convergence, manages turn order, and prevents runaway discussions. |
| ðŸ—ï¸âš¡ðŸ§ªðŸ”§ðŸŽ¨ðŸ˜ˆ... **Panelists** | Domain Experts | 3â€“8 AI experts, each with unique expertise and persona. They analyze, debate, critique, and refine positions until consensus emerges. |

### What Makes It Special

- **Multi-perspective analysis** â€” no single-agent blind spots
- **Structured debate** â€” not just multiple responses, but genuine back-and-forth critique
- **Convergence detection** â€” the system knows when experts agree and triggers synthesis automatically
- **Guard rails** â€” resource limits, time caps, and safety policies prevent runaway costs
- **Rich UI** â€” watch the debate unfold in real time across a three-pane layout
- **Follow-up Q&A** â€” ask questions after the synthesis to dig deeper

---

## 2. Why Use a Panel? â€” Value Proposition

### The Problem with Single-Agent Analysis

When you ask a single AI agent to review your architecture, audit your security, or analyze a complex topic, you get **one perspective**. That agent might be great at code review but miss the DevOps implications, or excellent at performance analysis but overlook UX concerns.

### The Panel Advantage

| Single Agent | Panel Discussion |
|---|---|
| One perspective, one pass | 3â€“8 experts, multiple rounds of analysis |
| No self-challenge | Experts critique each other's positions |
| May miss cross-domain impacts | Every domain is represented |
| Fixed depth of analysis | Depth adapts to complexity (Quick â†’ Standard â†’ Deep) |
| No convergence signal | You know when experts agree (convergence %) |
| One-shot output | Iterative refinement through structured debate |
| Flat response | Rich synthesis report with multi-perspective consensus |

### When to Use Panel Discussion

| âœ… Great For | âŒ Not Ideal For |
|---|---|
| Architecture decisions with multiple trade-offs | Simple coding questions |
| Security audits needing multi-angle analysis | Quick one-off tasks |
| Technology selection evaluations | File editing or code generation |
| Design reviews (code, UX, API) | Repetitive monitoring (use Agent Office) |
| Complex research questions | Large multi-file refactoring (use Agent Team) |
| Risk assessment and mitigation planning | Real-time incident response |
| Post-mortem analysis | Tasks requiring tool-heavy execution |
| Compliance and regulatory review | |

---

## 3. Quick Start â€” Your First Panel in 2 Minutes

### Step 1 â€” Open the Panel Tab

Click the **ðŸŽ™ Panel** tab in the main CopilotDesktop navigation bar.

### Step 2 â€” Enter Your Topic

Type your topic in the input box at the bottom:

```
Should we migrate our monolithic REST API to a microservices 
architecture using gRPC? Consider our team of 8 engineers, 
current 50ms p99 latency requirement, and 3-month timeline.
```

Click **ðŸŽ™ Start Panel** (or press Enter).

### Step 3 â€” Interact with the Head Agent

The Head Agent may ask clarifying questions in the **left pane**:

> ðŸŽ“ **Head Agent:** "Before I assemble the panel, I'd like to clarify:
> 1. What's your current tech stack?
> 2. What's driving the migration â€” performance, scalability, or team autonomy?
> 3. Are there any regulatory constraints on data flow between services?"

Answer naturally. The Head builds context before the debate begins.

### Step 4 â€” Review the Plan & Approve

The Head presents a discussion plan with selected panelists:

> **Discussion Plan:**
> - Depth: Standard (30 turns, 80% convergence)
> - Panelists: ðŸ—ï¸ Software Architect, âš¡ Performance Engineer, ðŸ”§ DevOps Engineer, ðŸ§ª QA Specialist, ðŸ˜ˆ Devil's Advocate
> - Focus areas: Service boundaries, data consistency, deployment complexity, testing strategy, risk assessment

Click **âœ… Approve & Start Panel** to launch the discussion.

### Step 5 â€” Watch the Debate Unfold

The **center pane** fills with expert analysis:

> ðŸ—ï¸ **Software Architect:** "Given the 8-person team and 3-month timeline, I'd recommend a modular monolith as a stepping stone..."
>
> âš¡ **Performance Engineer:** "The 50ms p99 requirement is tight. gRPC's binary protocol helps, but network hops between services add latency..."
>
> ðŸ˜ˆ **Devil's Advocate:** "Let's challenge the premise â€” is the monolith actually the bottleneck, or is this a Conway's Law reflex?"

### Step 6 â€” Read the Synthesis

When convergence reaches the threshold (default 80%), the system automatically produces a **Synthesis Report** â€” a comprehensive, multi-perspective conclusion.

### Step 7 â€” Ask Follow-Up Questions

After synthesis, you can ask follow-up questions:

```
What would the first 3 microservices be if we decided to go ahead?
```

The Head Agent answers with the full context of the panel debate.

---

## 4. Understanding the Interface

### 4.1 Three-Pane Layout Overview

The Panel Discussion interface uses a purpose-built three-pane layout:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸŽ™ Panel Discussion  [Phase]  [Depth]   Status   ðŸŽ¯ 75%  ðŸ”„ 12/30  ðŸ’° ~$0.42  [â¸][â–¶][â¹][ðŸ”„] [âš™]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸŸ¢ â— Panelists are debating service boundaries...  âš¡ Quick  ðŸ—ï¸ Architect  âš™ Parallel           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   â”‚                                  â”‚                   â”‚
â”‚  ðŸŽ“ Head Agent    â”‚  ðŸ—£ Discussion Stream  [12 msgs] â”‚  ðŸ” Agent Inspectorâ”‚
â”‚                   â”‚                                  â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ [Head] I've â”‚  â”‚  â”‚ ðŸ—ï¸ Software Architect       â”‚ â”‚  â”‚ ðŸ—ï¸ Architectâ”‚ â”‚
â”‚  â”‚ assembled a â”‚  â”‚  â”‚ Given the team size...      â”‚ â”‚  â”‚   Active    â”‚ â”‚
â”‚  â”‚ panel of 5  â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ experts...  â”‚  â”‚  â”‚ âš¡ Performance Engineer     â”‚ â”‚  â”‚ âš¡ Perf Eng â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  â”‚ The 50ms p99 constraint...  â”‚ â”‚  â”‚   Idle      â”‚ â”‚
â”‚  â”‚ [You] Our   â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ stack is    â”‚  â”‚  â”‚ ðŸ˜ˆ Devil's Advocate         â”‚ â”‚  â”‚ ðŸ˜ˆ Devil's  â”‚ â”‚
â”‚  â”‚ .NET 8 +    â”‚  â”‚  â”‚ Before we accept that...    â”‚ â”‚  â”‚   Idle      â”‚ â”‚
â”‚  â”‚ PostgreSQL  â”‚  â”‚  â”‚                             â”‚ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  [Details]  â”‚ â”‚
â”‚                   â”‚                                  â”‚  â”‚  Msgs: 4    â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                                  â”‚  â”‚  Tools: 2   â”‚ â”‚
â”‚  â”‚ ðŸ“‹ Review   â”‚  â”‚                                  â”‚  â”‚  Last: ...  â”‚ â”‚
â”‚  â”‚ [âœ… Approve]â”‚  â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚ [âŒ Reject] â”‚  â”‚                                  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                                  â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â–¶ Enter a topic to start a panel discussion...                 [Send]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Pane | Purpose | What to Watch For |
|---|---|---|
| **Left** (280px) | Your 1:1 chat with the Head Agent | Clarification Q&A, plan review, approval buttons |
| **Center** (flexible) | The live discussion stream â€” all panelists debating | Expert analysis, cross-critiques, commentary notes |
| **Right** (240px) | Agent Inspector â€” select any agent to see stats | Status, message count, tool calls, last activity |

All three panes are **resizable** â€” drag the splitters between them.

### 4.2 Header Bar â€” Your Command Center

The header bar is the nerve center, packed with real-time indicators and controls:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸŽ™ Panel Discussion  [Phase Badge] [Depth Badge]   ðŸ” Status Text      â”‚
â”‚                                       ðŸŽ¯ 75%  ðŸ”„ 12/30  ðŸ’° ~$0.42      â”‚
â”‚                                       [â¸ Pause] [â–¶ Resume] [â¹ Stop] [ðŸ”„ Reset]  [âš™]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Element | Description |
|---|---|
| **Phase Badge** | Shows current lifecycle phase (e.g., `Clarifying`, `Running`, `Synthesizing`) with color coding |
| **Depth Badge** | Appears after the Head Agent detects discussion depth: `âš¡ Quick`, `ðŸ“ Standard`, `ðŸ”¬ Deep` |
| **Status Icon + Text** | Center-aligned status description (e.g., `ðŸ” Analyzing topic complexity...`) |
| **ðŸŽ¯ Convergence %** | How close the panelists are to consensus (teal badge) |
| **ðŸ”„ Turns Display** | Current turn / max turns (blue badge) |
| **ðŸ’° Cost Display** | Estimated API cost for the session (amber badge) |
| **Action Buttons** | â¸ Pause, â–¶ Resume, â¹ Stop, ðŸ”„ Reset |
| **âš™ Settings Gear** | Opens the side panel (settings + event log). Red badge shows pending unsaved changes |

### 4.3 Execution Bar â€” Live Pulse

When the discussion is active, a green pulsing bar appears below the header showing real-time execution state:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â— Panelists are debating...  â”‚  âš¡ Quick  â”‚  ðŸ—ï¸ Architect  â”‚  âš™ Parallel  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Column | What It Shows |
|---|---|
| **Status Text** | Green dot + animated description of current activity |
| **Discussion Mode Badge** | Color-coded depth indicator â€” see [Discussion Depth](#6-discussion-depth--controlling-analysis-intensity) |
| **Active Agent** | Which panelist is currently speaking (green pill with name/icon) |
| **Parallel Indicator** | Shows `âš™ Parallel` when multiple agents are active simultaneously |

**Discussion Mode Badge Colors:**

| Depth | Badge Text | Background | Border/Text Color |
|---|---|---|---|
| âš¡ Quick | `âš¡ Quick` | Amber `#FFF8E1` | `#F57F17` |
| ðŸ“ Standard | `ðŸ“ Standard` | Blue `#E3F2FD` | `#1565C0` |
| ðŸ”¬ Deep | `ðŸ”¬ Deep` | Purple `#F3E5F5` | `#7B1FA2` |

### 4.4 Left Pane â€” Head Agent Chat

This is your private channel with the Head Agent. The Head is your representative on the panel â€” it:

1. **Clarifies** your topic (asks questions if needed)
2. **Builds** the discussion plan (selects panelists, sets parameters)
3. **Presents** the plan for your approval
4. **Manages** the discussion on your behalf
5. **Delivers** the final synthesis
6. **Answers** follow-up questions after completion

**Message Styles:**

| Sender | Background | Alignment |
|---|---|---|
| Head Agent | Blue `#E3F2FD` | Left |
| You | Indigo `#E8EAF6` | Right |

**Approval Banner:**

When the Head presents a plan, an amber banner appears at the bottom of the left pane:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“‹ Review the panel plan above â”‚
â”‚ [âœ… Approve & Start Panel]     â”‚
â”‚ [âŒ Reject]                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **âœ… Approve & Start Panel** â€” Launches the discussion immediately
- **âŒ Reject** â€” Rejects the plan; type feedback in the input box and the Head will revise

### 4.5 Center Pane â€” Discussion Stream

The main event. All panelist messages appear here in chronological order.

**Message Format:**

Each message shows:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [ðŸ—ï¸]  Software Architect  Â· Panelist      10:34:22  â”‚
â”‚                                                      â”‚
â”‚  Given the team size of 8 engineers and the          â”‚
â”‚  3-month timeline, I'd strongly recommend...         â”‚
â”‚  (Markdown rendered content)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Element | Description |
|---|---|
| **Role Icon** | Colored circle with emoji (matches the panelist's assigned icon) |
| **Author Name** | Panelist's display name (colored to match their role) |
| **Role Label** | `Head`, `Moderator`, `Panelist` in gray |
| **Timestamp** | HH:mm:ss format |
| **Content** | Full Markdown rendering (code blocks, lists, tables, emphasis) |

**Commentary Messages** (from the Moderator) are distinguished with a purple left border and lilac background (`#F3E5F5`).

**Pane Header Features:**
- ðŸ—£ "Discussion Stream" title with message count badge
- **Agent pill indicators** â€” small colored dots showing each agent's status (green = active, gray = idle)
- Click any agent pill to select it in the Agent Inspector

### 4.6 Right Pane â€” Agent Inspector

A live dashboard for monitoring individual agents.

**Agent List** (scrollable, max 200px height):
Each agent appears as a clickable card showing:
- Role icon + name
- Role label + message count
- Status dot (colored by current status)

**Selected Agent Detail Panel:**
When you click an agent, the detail section shows:
- **Header:** Icon, name, status badge, role
- **Stats Grid:**
  - Messages sent
  - Tool calls made
  - Last tool used
- **Last Message:** Most recent content from this agent

**How to Select an Agent:**
- Click an agent card in the right pane, or
- Click an agent pill in the center pane header

### 4.7 Bottom Input Bar

A unified input area that adapts based on the current phase:

| Phase | Placeholder Text | Button | Action |
|---|---|---|---|
| **Idle** | "Enter a topic to start a panel discussion..." | ðŸŽ™ Start Panel | Submits topic to Head Agent |
| **Clarifying** | "Send a message to the Head agent..." | Send | Sends answer to Head |
| **Running** | "Send a message to the Head agent..." | Send | Communicates with Head mid-discussion |
| **Completed** | "Ask a follow-up question..." | Send | Sends follow-up to Head for contextual answer |

The input supports **multi-line text** (press Shift+Enter for new lines, Enter to send).

### 4.8 Side Panel â€” Settings & Event Log

Click the **âš™** gear icon in the header to slide open the settings panel from the right.

```
â”Œâ”€â”€â”€ âš™ Panel Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [âœ•] â”€â”€â”
â”‚                                              â”‚
â”‚  ðŸ§  Model Selection                         â”‚
â”‚  â”œâ”€ Primary Model (Head/Moderator): [â–¾]     â”‚
â”‚  â””â”€ ðŸ¤– Panelist Model Pool: [â˜‘] [â˜‘] [â˜]   â”‚
â”‚                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚                                              â”‚
â”‚  ðŸŽ™ Panel Configuration   [â†© Defaults]      â”‚
â”‚  â”œâ”€ Max Panelists: [5]   Max Turns: [30]    â”‚
â”‚  â”œâ”€ Duration (min): [30] Convergence: [80]% â”‚
â”‚  â”œâ”€ Commentary: [Briefâ–¾] Depth: [Autoâ–¾]     â”‚
â”‚  â”œâ”€ â˜‘ Allow file system access               â”‚
â”‚  â””â”€ ðŸ“‚ Working Directory: [path] [ðŸ“]       â”‚
â”‚                                              â”‚
â”‚  [âš  3 unsaved changes]  [âœ“ Apply] [âœ• Disc] â”‚
â”‚                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚                                              â”‚
â”‚  ðŸ“ Event Log                                â”‚
â”‚  â”œâ”€ 10:34:12 PhaseChanged â†’ Running         â”‚
â”‚  â”œâ”€ 10:34:10 AgentMessage Architect          â”‚
â”‚  â”œâ”€ 10:33:58 ConvergenceUpdate 45%          â”‚
â”‚  â””â”€ ...                                     â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Model Selection:**

| Control | Description |
|---|---|
| **Primary Model** | Dropdown for Head + Moderator agents. Use your most capable model here. |
| **Panelist Model Pool** | Multi-select checkbox list. Each panelist is randomly assigned from this pool. Empty = all panelists use the primary model. |
| **ðŸ”„ Refresh** | Re-fetches available models from the Copilot SDK |

**Panel Configuration:**

| Setting | Default | Range | Description |
|---|---|---|---|
| **Max Panelists** | 5 | Dropdown | Maximum number of expert panelists in the discussion |
| **Max Turns** | 30 | Dropdown | Total turns across all panelists before forced convergence |
| **Max Duration** | 30 min | Dropdown | Wall-clock time limit for the entire discussion |
| **Convergence %** | 80 | 0â€“100 | Agreement threshold that triggers automatic synthesis |
| **Commentary Mode** | Brief | Detailed / Brief / Off | How much reasoning the moderator shares (see [Section 7](#7-commentary-mode--controlling-verbosity)) |
| **Discussion Depth** | Auto | Auto / Quick / Standard / Deep | Analysis intensity (see [Section 6](#6-discussion-depth--controlling-analysis-intensity)) |
| **File System Access** | âœ… | Checkbox | Whether panelists can use file system tools |
| **Working Directory** | (empty) | Path | Root directory for file system tools. Empty = default. |

**Pending Changes System:**
- Changes are tracked but **not applied immediately**
- An amber badge appears: `âš  3 unsaved change(s)`
- Click **âœ“ Apply** to save, or **âœ• Discard** to revert
- Some settings require a **Reset** to take effect (indicated by a yellow warning)
- The header gear icon shows a red badge with the count of pending changes

**Event Log:**
A reverse-chronological, monospace-formatted log of every significant event:
- Phase transitions
- Agent messages
- Convergence updates
- Tool calls
- Moderation decisions
- Errors

### 4.9 Synthesis Report Overlay

When the discussion converges, a modal overlay presents the synthesis:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“Š Panel Synthesis Report                    [âœ•]  â”‚
â”‚                                                    â”‚
â”‚  ## Executive Summary                              â”‚
â”‚  Based on the panel's analysis...                  â”‚
â”‚                                                    â”‚
â”‚  ## Key Findings                                   â”‚
â”‚  1. Architecture: Modular monolith recommended...  â”‚
â”‚  2. Performance: gRPC viable within latency...     â”‚
â”‚  3. Risk: Timeline too tight for full micro...     â”‚
â”‚                                                    â”‚
â”‚  ## Consensus Points                               â”‚
â”‚  - All panelists agree on phased migration...      â”‚
â”‚                                                    â”‚
â”‚  ## Dissenting Views                               â”‚
â”‚  - Devil's Advocate: Consider the null hypothesis  â”‚
â”‚                                                    â”‚
â”‚  ## Recommendations                                â”‚
â”‚  1. Start with modular monolith...                 â”‚
â”‚  2. Extract first service after 6 months...        â”‚
â”‚                                                    â”‚
â”‚                        [ðŸ“‹ Copy]  [âœ• Close]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Markdown rendered** â€” full formatting with headers, lists, code blocks, tables
- **ðŸ“‹ Copy** â€” copies the full synthesis text to clipboard
- **âœ• Close** â€” dismisses the overlay (you can still access the synthesis via follow-up questions)
- **Click backdrop** to dismiss

---

## 5. The Discussion Lifecycle â€” From Topic to Synthesis

Every panel discussion follows an 11-phase lifecycle:

### Visual Flow

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   IDLE   â”‚ â—„â”€â”€ Ready for a topic
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚ User submits topic
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  CLARIFYING  â”‚ â—„â”€â”€ Head asks questions (optional)
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Topic is clear
                         â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  AWAITING APPROVAL    â”‚ â—„â”€â”€ Plan ready for review
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ User approves
                         â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ PREPARING â”‚ â—„â”€â”€ Creating agent sessions
                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚ All agents ready
                         â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  RUNNING  â”‚ â—„â”€â”€ Panelists debating
                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”œâ”€â”€â”€â”€â”€ User pauses â”€â”€â–ºâ”‚ PAUSED  â”‚
                         â”‚                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚                         â”‚ User resumes
                         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Convergence threshold met
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  CONVERGING  â”‚ â—„â”€â”€ Final round of refinement
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  SYNTHESIZING  â”‚ â—„â”€â”€ Head compiles the report
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ COMPLETED â”‚ â—„â”€â”€ Synthesis available + follow-up Q&A
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    At any point:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STOPPED  â”‚       â”‚  FAILED  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    (user clicked Stop)  (unrecoverable error)
```

### Phase-by-Phase Walkthrough

| # | Phase | What Happens | Your Role |
|---|---|---|---|
| 1 | **Idle** | Panel is ready. No active discussion. | Enter a topic in the input box. |
| 2 | **Clarifying** | Head Agent analyzes your topic and may ask questions to narrow scope. | Answer the Head's questions in the left pane. |
| 3 | **AwaitingApproval** | Head presents a discussion plan with selected panelists, depth, and focus areas. | Review and click âœ… Approve or âŒ Reject. |
| 4 | **Preparing** | System creates Copilot sessions for each panelist. Agents initialize. | Wait â€” this takes 5â€“15 seconds. |
| 5 | **Running** | Panelists analyze and debate. Messages stream into the center pane. Convergence rises. | Watch, learn, and optionally send messages to the Head. |
| 6 | **Paused** | Discussion frozen. No new turns. | Click â–¶ Resume when ready. |
| 7 | **Converging** | Moderator detected sufficient agreement. Final refinement round. | Observe â€” this is brief. |
| 8 | **Synthesizing** | Head Agent compiles all perspectives into a comprehensive report. | Wait â€” synthesis takes 10â€“30 seconds. |
| 9 | **Completed** | Synthesis report displayed. Follow-up Q&A available. | Read the report. Ask follow-up questions. |
| 10 | **Stopped** | User manually stopped the discussion. | Click ðŸ”„ Reset to start fresh. |
| 11 | **Failed** | An unrecoverable error occurred. | Check the event log. Click ðŸ”„ Reset. |

---

## 6. Discussion Depth â€” Controlling Analysis Intensity

Discussion Depth determines how thoroughly the panel analyzes your topic. It controls the number of debate turns, the convergence threshold, and the overall analysis intensity.

### The Four Depth Levels

| Depth | Icon | Max Turns | Convergence Threshold | Best For |
|---|---|---|---|---|
| **Auto** | ðŸ¤– | (detected) | (detected) | Most topics â€” let the Head Agent decide |
| **Quick** | âš¡ | 10 | 60% | Simple trade-off questions, quick reviews, time-sensitive decisions |
| **Standard** | ðŸ“ | 30 | 80% | Architecture reviews, design decisions, most analysis tasks |
| **Deep** | ðŸ”¬ | 50 | 90% | Complex research, compliance audits, critical architecture decisions |

### How Auto Detection Works

When set to **Auto** (default), the Head Agent analyzes your topic's complexity and selects the appropriate depth. The detected depth appears as a badge in the header bar.

**Factors the Head considers:**
- Topic complexity and scope
- Number of competing trade-offs
- Presence of safety/compliance implications
- Whether the topic spans multiple domains
- Explicit user cues ("quick review" â†’ Quick, "deep analysis" â†’ Deep)

### How to Override

1. Open the **âš™ Side Panel**
2. Under **Panel Configuration**, find **Discussion Depth**
3. Select `Quick`, `Standard`, or `Deep` from the dropdown
4. Click **âœ“ Apply**

> **Tip:** Use `Auto` for most topics. Override to `Quick` when you're time-pressed, or to `Deep` when the decision is critical and you want maximum rigor.

---

## 7. Commentary Mode â€” Controlling Verbosity

Commentary Mode controls how much behind-the-scenes reasoning the Moderator agent shares in the discussion stream.

| Mode | What You See | Best For |
|---|---|---|
| **Detailed** | All Moderator reasoning: convergence calculations, turn-order decisions, guard rail checks | Learning how the system works; debugging unexpected behavior |
| **Brief** | Key decisions only: convergence milestones, phase transitions, notable moderation actions | Normal usage â€” stays informed without noise |
| **Off** | No commentary. Only panelist contributions appear. | Clean reading experience; maximum focus on content |

**Commentary messages** appear in the center pane with a distinctive purple left border and lilac background, making them easy to distinguish from panelist analysis.

### How to Change

1. Open the **âš™ Side Panel**
2. Under **Panel Configuration**, find **Commentary Mode**
3. Select `Detailed`, `Brief`, or `Off`
4. Click **âœ“ Apply**

---

## 8. Meet the Panelists â€” Default Expert Profiles

CopilotDesktop includes 8 pre-built expert profiles. The Head Agent selects the most relevant subset for each discussion.

| # | Icon | Name | Expertise | Persona | Priority | Tools |
|---|---|---|---|---|---|---|
| 1 | ðŸ›¡ï¸ | **Security Expert** | Identifies vulnerabilities, auth/authz issues, data exposure risks, and compliance gaps | Thorough and cautious â€” flags risks others overlook | 1 (highest) | âœ… |
| 2 | âš¡ | **Performance Engineer** | Analyzes latency, throughput, memory, algorithmic complexity, and scalability bottlenecks | Data-driven â€” demands benchmarks and evidence | 2 | âœ… |
| 3 | ðŸ—ï¸ | **Software Architect** | Evaluates system design, patterns, modularity, extensibility, and technical debt | Strategic thinker â€” balances ideals with pragmatism | 3 | âœ… |
| 4 | ðŸ§ª | **QA Specialist** | Focuses on testability, edge cases, regression risks, and quality metrics | Detail-oriented â€” asks "what could go wrong?" | 4 | âœ… |
| 5 | ðŸ”§ | **DevOps Engineer** | Covers deployment, CI/CD, observability, infrastructure, and operational readiness | Practical â€” cares about what happens at 3 AM | 5 | âœ… |
| 6 | ðŸŽ¨ | **UX Advocate** | Evaluates user experience, API ergonomics, developer experience, and accessibility | Empathetic â€” represents the end user's perspective | 6 | âœ… |
| 7 | ðŸ“‹ | **Domain Expert** | Provides business context, regulatory knowledge, and domain-specific constraints | Knowledgeable â€” bridges tech and business | 7 | âœ… |
| 8 | ðŸ˜ˆ | **Devil's Advocate** | Challenges assumptions, questions premises, and stress-tests conclusions | Contrarian â€” ensures the panel doesn't fall into groupthink | 8 | âœ… |

### Panelist Colors

Each panelist is assigned a unique color for visual identification in the discussion stream:

| Panelist | Color |
|---|---|
| ðŸ›¡ï¸ Security Expert | Red `#D32F2F` |
| âš¡ Performance Engineer | Amber `#F57F17` |
| ðŸ—ï¸ Software Architect | Indigo `#303F9F` |
| ðŸ§ª QA Specialist | Green `#388E3C` |
| ðŸ”§ DevOps Engineer | Blue-Gray `#455A64` |
| ðŸŽ¨ UX Advocate | Pink `#C2185B` |
| ðŸ“‹ Domain Expert | Teal `#00796B` |
| ðŸ˜ˆ Devil's Advocate | Deep Purple `#512DA8` |

### How Panelists Are Selected

The Head Agent selects panelists based on:
1. **Topic relevance** â€” a security audit will prioritize the Security Expert
2. **Diversity** â€” ensures multiple perspectives are represented
3. **Max panelists setting** â€” respects the configured limit (default 5)
4. **Priority order** â€” when all else is equal, lower priority number = selected first

---

## 9. Preset Panels â€” Ready-Made Expert Teams

For common use cases, CopilotDesktop includes preset panel configurations:

### âš¡ QuickPanel (3 experts)

| Panelist | Why Included |
|---|---|
| ðŸ—ï¸ Software Architect | Core design perspective |
| ðŸ›¡ï¸ Security Expert | Critical safety coverage |
| âš¡ Performance Engineer | Non-functional requirements |

**Best for:** Quick design reviews, focused technical decisions, time-boxed analysis.

### ðŸ“ BalancedPanel (5 experts)

| Panelist | Why Included |
|---|---|
| ðŸ—ï¸ Software Architect | Design leadership |
| ðŸ›¡ï¸ Security Expert | Security coverage |
| âš¡ Performance Engineer | Performance analysis |
| ðŸ§ª QA Specialist | Quality and testability |
| ðŸ˜ˆ Devil's Advocate | Assumption-challenging |

**Best for:** Architecture reviews, technology evaluations, comprehensive design decisions.

---

## 10. Convergence â€” How Consensus Emerges

Convergence is the panel's measure of how much the experts agree. It's displayed as a percentage in the header bar (ðŸŽ¯ badge).

### How It Works

The **Convergence Detector** service analyzes panelist messages and scores agreement:

| Convergence % | Meaning | Visual |
|---|---|---|
| 0â€“30% | **Divergent** â€” experts have fundamentally different views | ðŸŽ¯ Red/low |
| 30â€“60% | **Emerging** â€” some common ground, but significant disagreements | ðŸŽ¯ Amber |
| 60â€“80% | **Aligning** â€” broad agreement with minor differences | ðŸŽ¯ Green |
| 80â€“100% | **Converged** â€” strong consensus reached | ðŸŽ¯ Bright green |

### What Triggers Synthesis

Synthesis is automatically triggered when **either** of these conditions is met:

1. **Convergence threshold reached** â€” the convergence % meets or exceeds your configured threshold (default 80%)
2. **Max turns exhausted** â€” the discussion hits the maximum turn count (forced convergence)
3. **Max duration exceeded** â€” the wall-clock time limit is reached

The Moderator agent monitors these conditions on every turn.

### Adjusting the Threshold

- **Lower threshold (60â€“70%)** â€” faster synthesis, but may include more unresolved disagreements
- **Default (80%)** â€” good balance of thoroughness and efficiency
- **Higher threshold (90%+)** â€” very thorough, but discussions may run longer

Change it in **âš™ Side Panel â†’ Convergence (%)**.

---

## 11. Guard Rails â€” Safety & Resource Limits

Every panel discussion is governed by a **Guard Rail Policy** that prevents runaway costs, infinite loops, and unsafe content.

### Default Limits

| Guard Rail | Default | Range | Description |
|---|---|---|---|
| **Max Turns** | 30 | 5â€“100 | Total turns across all panelists |
| **Max Tokens/Turn** | 4,000 | â€” | Maximum tokens a single panelist can produce per turn |
| **Max Total Tokens** | 100,000 | 10Kâ€“500K | Token budget for the entire discussion |
| **Max Tool Calls/Turn** | 5 | â€” | Tool calls per panelist per turn |
| **Max Tool Calls Total** | 50 | 10â€“200 | Tool call budget for the entire discussion |
| **Max Duration** | 30 min | 5â€“120 min | Wall-clock time limit |
| **Max Single Turn Duration** | 3 min | â€” | Timeout for any single agent's turn |
| **Max Critique Rounds** | 2 | â€” | Maximum refine-critique iterations per topic before force-accept |

### What Happens When Limits Are Hit

1. **The Moderator detects the limit violation**
2. **Commentary message** appears in the discussion stream (if Commentary Mode is Brief or Detailed)
3. **Depending on severity:**
   - **Turn limit / duration** â†’ Moderator forces convergence, discussion moves to Synthesizing
   - **Token budget** â†’ Current turn is truncated; discussion forced to converge
   - **Tool call limit** â†’ Further tool calls are blocked for the current turn/discussion
   - **Prohibited content** â†’ Message is blocked and not shown to other panelists

### Resilience Features

| Feature | Description |
|---|---|
| **Tool Circuit Breaker** | If a tool fails repeatedly, it's temporarily disabled to prevent cascading failures |
| **Retry Policy** | Transient failures are retried with exponential backoff |
| **Sandboxed Tool Executor** | Tool calls run in isolation to prevent cross-contamination between agents |
| **Cost Estimation** | Real-time cost tracking displayed in the header (ðŸ’° badge) |

---

## 12. Settings Reference

Complete reference for all configurable settings:

### Model Settings

| Setting | Where | Default | Description |
|---|---|---|---|
| Primary Model | Side Panel â†’ Model Selection | (first available) | Model for Head + Moderator agents. Use your best model. |
| Panelist Models | Side Panel â†’ Model Pool | (empty = primary) | Pool of models for panelists. Random assignment. Empty means all use primary. |

### Discussion Settings

| Setting | Where | Default | Range | Description |
|---|---|---|---|---|
| Max Panelists | Side Panel â†’ Panel Config | 5 | Dropdown | Maximum number of expert panelists |
| Max Turns | Side Panel â†’ Panel Config | 30 | Dropdown | Total turn budget |
| Max Duration | Side Panel â†’ Panel Config | 30 min | Dropdown | Wall-clock time limit |
| Convergence Threshold | Side Panel â†’ Panel Config | 80% | 0â€“100 | Agreement % that triggers synthesis |
| Commentary Mode | Side Panel â†’ Panel Config | Brief | Detailed/Brief/Off | Moderator verbosity |
| Discussion Depth | Side Panel â†’ Panel Config | Auto | Auto/Quick/Standard/Deep | Analysis intensity |
| File System Access | Side Panel â†’ Panel Config | âœ… | Checkbox | Whether agents can use file system tools |
| Working Directory | Side Panel â†’ Panel Config | (empty) | Path | Root for file system tools |

### How Settings Are Applied

1. **Change settings** in the side panel
2. **Pending changes indicator** appears with count
3. Click **âœ“ Apply** to save
4. Some settings (model, panelists) require a **ðŸ”„ Reset** to take effect on the next discussion
5. Click **â†© Defaults** to restore all settings to factory defaults

---

## 13. Phase Reference

| Phase | Badge Color | Status Icon | Description |
|---|---|---|---|
| **Idle** | Gray | ðŸ’¤ | No active discussion. Ready for input. |
| **Clarifying** | Amber | â“ | Head Agent is asking you questions about the topic. |
| **AwaitingApproval** | Blue | ðŸ“‹ | Discussion plan ready for your review. |
| **Preparing** | Purple | â³ | Creating agent sessions and initializing panelists. |
| **Running** | Green | ðŸŸ¢ | Panelists are actively debating. Convergence is rising. |
| **Paused** | Orange | â¸ | Discussion frozen by user. No turns being processed. |
| **Converging** | Teal | ðŸŽ¯ | Final refinement round after convergence threshold met. |
| **Synthesizing** | Purple | ðŸ“Š | Head Agent is compiling the synthesis report. |
| **Completed** | Green | âœ… | Synthesis available. Follow-up Q&A enabled. |
| **Stopped** | Gray | â¹ | User manually stopped the discussion. |
| **Failed** | Red | ðŸ”´ | Unrecoverable error. Check event log. |

---

## 14. Agent Role Reference

| Role | Icon | Count | Lifecycle | Responsibilities |
|---|---|---|---|---|
| **Head** | ðŸŽ“ | 1 per discussion | Lives for entire discussion | User interaction, clarification, plan building, panelist selection, synthesis, follow-up Q&A |
| **Moderator** | ðŸ›¡ï¸ | 1 per discussion | Lives for entire discussion | Guard rail enforcement, convergence detection, turn management, safety filtering |
| **Panelist** | Various | 3â€“8 per discussion | Lives for entire discussion | Domain-specific analysis, cross-critique, evidence gathering, position refinement |
| **User** | ðŸ‘¤ | 1 | â€” | Submits topics, answers clarifications, approves plans, asks follow-ups |

### Agent Status States

| Status | Color | Meaning |
|---|---|---|
| **Idle** | Gray | Agent created but not currently active |
| **Active** | Green | Agent is currently producing a response |
| **WaitingForTurn** | Blue | Agent is queued and waiting for its turn |
| **Completed** | Dark Green | Agent has finished all contributions |
| **Failed** | Red | Agent encountered an error |
| **Disposed** | Gray | Agent session has been cleaned up |

---

## 15. Worked Example â€” Architecture Review

### Scenario
You're leading a team deciding whether to use event sourcing for a new order management system.

---

**Step 1 â€” Enter the Topic**

```
Should we use event sourcing for our new order management system? 
We expect 10K orders/day, need audit trails, and have a team of 
6 engineers with no prior event sourcing experience.
```

**Step 2 â€” Head Clarification**

> ðŸŽ“ **Head Agent:** "Before I assemble the panel, a few questions:
> 1. What's your current data store? (SQL, NoSQL, mixed?)
> 2. Do you need to support CQRS as well, or just event sourcing?
> 3. What's your deployment target? (Cloud provider, Kubernetes, bare metal?)
> 4. Any existing event infrastructure? (Kafka, RabbitMQ, EventStoreDB?)"

> **You:** "PostgreSQL. Open to CQRS if the panel recommends it. AWS EKS. 
> We have Kafka for messaging but haven't used it for event sourcing."

**Step 3 â€” Plan & Approve**

> ðŸŽ“ **Head Agent:**
> ## Discussion Plan
> **Depth:** Standard (ðŸ“ 30 turns, 80% convergence)
> 
> **Panelists Selected:**
> | # | Expert | Focus Area |
> |---|---|---|
> | 1 | ðŸ—ï¸ Software Architect | Event sourcing patterns, CQRS design, aggregate boundaries |
> | 2 | âš¡ Performance Engineer | 10K orders/day throughput, read-model projection latency |
> | 3 | ðŸ”§ DevOps Engineer | Kafka + EventStoreDB ops, EKS deployment, schema evolution |
> | 4 | ðŸ§ª QA Specialist | Testing event-sourced systems, replay testing, snapshot validation |
> | 5 | ðŸ˜ˆ Devil's Advocate | Challenge the event sourcing premise, simpler alternatives |

You click **âœ… Approve & Start Panel**.

**Step 4 â€” Watch the Debate**

```
ðŸ—ï¸ Software Architect                                         10:34:22
  Event sourcing is a natural fit for order management â€” orders have 
  a clear lifecycle (created â†’ confirmed â†’ shipped â†’ delivered) that 
  maps perfectly to an event stream. With 10K orders/day (~0.12/sec),
  the write throughput is modest. I'd recommend...

âš¡ Performance Engineer                                        10:34:45
  Agreed on throughput being manageable. But let's talk about read-side
  projections. If you need real-time dashboards, projection lag becomes
  critical. With Kafka + PostgreSQL read models, expect 50-200ms lag...

ðŸ˜ˆ Devil's Advocate                                            10:35:08
  Before we deep-dive event sourcing, has anyone considered that a 
  simple audit_log table with triggers on a standard CRUD model gives 
  you 90% of the audit trail benefit with 10% of the complexity? 
  The team has zero ES experience and a deadline...

ðŸ”§ DevOps Engineer                                             10:35:32
  The Devil raises a good point about operational complexity. Running
  EventStoreDB on EKS adds a stateful workload. Kafka you already have,
  but schema evolution with Avro/Protobuf needs governance from day 1...

ðŸ§ª QA Specialist                                               10:35:55
  Testing is my biggest concern. Event-sourced systems need:
  1. Event schema compatibility tests
  2. Projection correctness tests  
  3. Snapshot + replay verification
  None of these exist in your current test suite...

  [Moderator Commentary] ðŸŽ¯ Convergence: 35% â€” significant disagreement
  between event sourcing advocates and the simpler-alternatives camp.

ðŸ—ï¸ Software Architect                                         10:36:18
  Fair points from everyone. Let me propose a middle ground: start with
  a hybrid approach. Use standard CRUD with an append-only event log 
  table for audit. This gives you the audit trail immediately. Then 
  migrate to full event sourcing in phase 2 once the team has learned...

ðŸ˜ˆ Devil's Advocate                                            10:36:42
  Now that's pragmatic. The hybrid approach addresses the team 
  experience gap while preserving optionality. I withdraw my objection
  if we frame this as a phased adoption...

  [Moderator Commentary] ðŸŽ¯ Convergence: 72% â€” rapid alignment around 
  the phased approach. Continuing for refinement...
```

**Step 5 â€” Synthesis Report**

> ## ðŸ“Š Panel Synthesis Report
> 
> ### Executive Summary
> The panel recommends a **phased approach** to event sourcing for the order management system, starting with a CRUD + audit trail hybrid and evolving toward full event sourcing.
> 
> ### Consensus Points (92% agreement)
> 1. **Phase 1 (Months 1â€“3):** Standard CRUD with PostgreSQL + append-only event log table for audit trails
> 2. **Phase 2 (Months 4â€“6):** Introduce CQRS read models using Kafka projections from the event log
> 3. **Phase 3 (Month 7+):** Full event sourcing with EventStoreDB if Phase 2 validates the pattern
> 
> ### Key Trade-offs
> | Factor | Full ES Now | Phased Approach |
> |---|---|---|
> | Team risk | High (no experience) | Low (learn incrementally) |
> | Audit trail | Immediate | Immediate |
> | Complexity | High from day 1 | Incremental |
> | Time to production | 4+ months | 2 months for Phase 1 |
> 
> ### Dissenting Views
> - âš¡ Performance Engineer notes that the phased approach may require data migration between phases
> - ðŸ—ï¸ Architect recommends designing Phase 1 tables with ES migration in mind (append-only, immutable events)
> 
> ### Recommendations
> 1. Design the event log table as if it were an event store (immutable, append-only, with version numbers)
> 2. Invest in Kafka consumer literacy during Phase 1
> 3. Budget 2 sprints for the Phase 1 â†’ Phase 2 migration
> 4. Add event schema compatibility testing from Phase 1

**Step 6 â€” Follow-Up**

```
You: "What should the event log table schema look like for Phase 1?"
```

The Head Agent answers with full context from the entire panel discussion.

---

## 16. Worked Example â€” Security Audit

### Scenario
You want the panel to audit a REST API's authentication and authorization implementation.

**Topic:**
```
Audit the authentication and authorization implementation in our 
REST API. We use JWT tokens with RS256, role-based access control, 
and API key authentication for service-to-service calls. The API 
handles PII data and must comply with SOC 2.
```

**Panel Selected:** ðŸ›¡ï¸ Security Expert (lead), ðŸ—ï¸ Architect, ðŸ“‹ Domain Expert (compliance), ðŸ§ª QA Specialist, ðŸ˜ˆ Devil's Advocate

**Discussion Highlights:**

```
ðŸ›¡ï¸ Security Expert                                            14:02:10
  Let me start with the JWT implementation. Key concerns:
  1. Token lifetime â€” what's the expiry? Anything > 15 min needs refresh
  2. RS256 key rotation â€” how often? Where are keys stored?
  3. Token revocation â€” JWTs are stateless; how do you invalidate?
  4. Are you checking 'aud' and 'iss' claims?

ðŸ“‹ Domain Expert                                               14:02:35
  For SOC 2 compliance, we need to verify:
  - All PII access is logged with immutable audit trails
  - Service-to-service API keys have rotation schedules
  - There's a formal access review process for RBAC roles
  - Encryption at rest and in transit for all PII fields

ðŸ˜ˆ Devil's Advocate                                            14:03:01
  Has anyone verified that the "role-based" access control is actually
  role-based and not just permission flags masquerading as RBAC? I've
  seen many APIs claim RBAC but implement flat permission checks...
```

**Synthesis Output:** A structured audit report with findings categorized by severity (Critical / High / Medium / Low), SOC 2 compliance gaps, and a prioritized remediation plan.

---

## 17. Worked Example â€” Deep Research Question

### Scenario
You're evaluating database technologies for a time-series IoT platform.

**Topic:**
```
Deep analysis: Which time-series database should we use for an IoT 
platform ingesting 1M data points/second from 100K sensors? Evaluate 
TimescaleDB, InfluxDB, QuestDB, and ClickHouse. We need 90-day hot 
storage, 2-year cold storage, and sub-second query latency for 
dashboards. Budget: $5K/month infrastructure.
```

**Depth Override:** ðŸ”¬ Deep (50 turns, 90% convergence)

**Panel Selected:** âš¡ Performance Engineer (lead), ðŸ—ï¸ Architect, ðŸ”§ DevOps Engineer, ðŸ’° Domain Expert (cost analysis), ðŸ˜ˆ Devil's Advocate

This discussion runs longer, with multiple rounds of analysis, benchmark comparisons, and cost modeling. The synthesis includes a detailed comparison matrix and a recommended architecture with specific configuration guidance.

---

## 18. Best Practices & Tips

### Writing Effective Topics

| âœ… Do | âŒ Don't |
|---|---|
| Be specific about constraints (timeline, team size, budget) | Submit vague topics ("review my code") |
| Mention relevant technologies and versions | Assume the panel knows your stack |
| State the decision you need to make | Ask open-ended questions with no focus |
| Include success criteria or non-functional requirements | Omit critical constraints |
| Mention compliance/regulatory requirements if relevant | Forget to mention security sensitivity |

**Good topics:**
- âœ… "Should we migrate from REST to gRPC for our internal services? Team of 12, .NET 8, latency budget is 20ms p99."
- âœ… "Review our caching strategy: Redis for sessions, Memcached for API responses, CDN for static assets. 50K concurrent users."
- âœ… "Evaluate authentication approaches for our mobile app: OAuth2 + PKCE vs. magic links vs. passkeys. SOC 2 required."

**Weak topics:**
- âŒ "Is microservices good?" (too vague)
- âŒ "Fix my code" (not a discussion topic â€” use the Chat tab)
- âŒ "Everything about Kubernetes" (no decision to make, no constraints)

### Optimizing Discussion Settings

| Goal | Depth | Panelists | Convergence | Commentary |
|---|---|---|---|---|
| Quick decision gut-check | Quick | 3 | 60% | Off |
| Standard architecture review | Standard | 5 | 80% | Brief |
| Critical security/compliance audit | Deep | 5â€“7 | 90% | Detailed |
| Exploratory research | Deep | 5 | 70% | Brief |
| Time-boxed meeting replacement | Quick | 3â€“4 | 60% | Off |

### During the Discussion

- **Watch the convergence indicator** â€” it tells you how close the panel is to consensus
- **Use the Agent Inspector** â€” click on the most active agent to understand their reasoning
- **Commentary mode = Brief** is the sweet spot â€” you see key decisions without noise
- **Don't interrupt unless needed** â€” the panel self-manages through the Moderator
- **Send messages to the Head** if you want to redirect the discussion

### After the Discussion

- **Copy the synthesis** â€” it's the most valuable artifact
- **Ask follow-up questions** â€” the Head retains full context
- **Start a new panel** for a follow-up topic â€” the panels are independent
- **Check the event log** if anything seemed unexpected

### Model Selection Strategy

| Agent | Recommended Model Tier | Why |
|---|---|---|
| Head + Moderator (Primary) | Best available (GPT-4o, Claude 3.5 Sonnet) | They orchestrate, synthesize, and make meta-decisions |
| Panelists | Good tier (GPT-4o-mini, Claude Haiku) | They analyze and debate; quantity matters more than individual brilliance |

**Cost optimization:** Using a cheaper model for the panelist pool and a premium model for the Primary can reduce costs by 50â€“70% with minimal quality impact.

---

## 19. How Panel Discussion Differs from Agent Team & Agent Office

| Aspect | ðŸ’¬ Panel Discussion | ðŸ‘¥ Agent Team | ðŸ¢ Agent Office |
|---|---|---|---|
| **Purpose** | Multi-expert debate & synthesis | Parallel task execution | Continuous monitoring & delegation |
| **Agents** | Experts with personas + opinions | Workers with specialized roles | Manager + ephemeral assistants |
| **Interaction Pattern** | Debate â†’ converge â†’ synthesize | Plan â†’ execute â†’ consolidate | Loop: fetch â†’ delegate â†’ report â†’ rest |
| **Agent Communication** | Agents see and critique each other | Agents work independently | Assistants report to Manager only |
| **Output** | Synthesis report with consensus + dissent | Consolidated work product | Iteration reports with recommendations |
| **Lifecycle** | Single discussion â†’ completion | Single batch â†’ completion | Continuous loop until stopped |
| **User Role** | Submit topic, approve, read synthesis | Submit task, approve plan, review | Define mission, approve, inject mid-run |
| **Best For** | Analysis, decisions, reviews, research | Refactoring, test gen, code changes | Incident monitoring, PR review, triage |
| **Duration** | 2â€“30 minutes | 5â€“60 minutes | Hours to days |
| **Key Metric** | Convergence % | Task completion % | Iteration count + success rate |

**Decision Guide:**
- ðŸ¤” **"I need multiple perspectives on a decision"** â†’ **Panel Discussion**
- ðŸ”¨ **"I need to execute a complex multi-step task"** â†’ **Agent Team**
- ðŸ”„ **"I need ongoing, periodic monitoring"** â†’ **Agent Office**

---

## 20. Troubleshooting

### Common Issues

| Symptom | Likely Cause | Resolution |
|---|---|---|
| Start button does nothing | No active Copilot session | Check health indicator; re-authenticate |
| Head never asks questions, goes straight to plan | Topic was clear enough | This is normal â€” clarification is optional |
| Discussion feels shallow | Depth set to Quick or Auto-detected as simple | Override to Standard or Deep in settings |
| Convergence stuck at 0% | Panelists fundamentally disagree | Wait for more turns; the Moderator will guide convergence. Or stop and narrow the topic. |
| Convergence stuck at 100% | Topic too simple for multi-agent debate | Expected for straightforward questions. Use Chat tab instead. |
| "PENDING â€” Reset to apply" won't go away | Changed settings that require a session restart | Click ðŸ”„ Reset, then start a new discussion |
| Side panel won't open | UI state conflict | Click the âš™ gear icon again; switch tabs and back if needed |
| Agent Inspector shows no agents | Discussion hasn't started yet | Agents appear after the Preparing phase completes |
| Synthesis overlay is empty | Synthesis still generating | Wait for the Synthesizing phase to complete |
| Discussion stops unexpectedly | Guard rail limit hit (turns, duration, tokens) | Check event log for the specific limit. Increase limits in settings. |
| Panelists all say the same thing | Topic has clear consensus | This is valid â€” the panel agrees. Check dissenting views in synthesis. |
| Cost seems high | Many turns + expensive model | Use cheaper models in panelist pool. Reduce depth. Lower max turns. |

### Performance Considerations

- **5+ panelists** with Deep depth can generate 50+ LLM calls â€” factor in API quota
- **File system tools** add latency if agents are reading large files
- **Commentary Mode = Detailed** increases moderator output but adds informational value
- **Very long discussions** (50+ turns) produce large context â€” synthesis quality may degrade slightly

### Error Recovery

1. **Single agent failure:** The Moderator skips the failed agent's turn and continues. The agent may recover on later turns.
2. **Head Agent failure:** The phase transitions to Failed. Check event log and Reset.
3. **Network disconnection:** The system attempts reconnection with context replay. If it fails, the phase transitions to Failed.
4. **Tool circuit breaker open:** A frequently-failing tool is temporarily disabled. Other tools continue working. The circuit breaker resets after a cooldown period.

---

## 21. Glossary

| Term | Definition |
|---|---|
| **Panel Discussion** | A structured multi-expert AI debate on a user-submitted topic |
| **Head Agent** | The primary agent that manages user interaction, builds discussion plans, and produces the final synthesis |
| **Moderator** | The behind-the-scenes agent that enforces guard rails, detects convergence, and manages turn order |
| **Panelist** | An AI agent with a specific expertise persona (e.g., Security Expert, Performance Engineer) |
| **Discussion Depth** | The configured intensity level: Quick (10 turns), Standard (30 turns), or Deep (50 turns) |
| **Commentary Mode** | How much Moderator reasoning is visible: Detailed, Brief, or Off |
| **Convergence** | A percentage (0â€“100%) measuring how much the panelists agree on key points |
| **Convergence Threshold** | The agreement percentage that triggers automatic synthesis (default 80%) |
| **Synthesis** | The Head Agent's comprehensive report combining all panel perspectives into consensus findings, dissenting views, and recommendations |
| **Guard Rail Policy** | Safety and resource limits that prevent runaway discussions (turn limits, token budgets, time caps) |
| **Tool Circuit Breaker** | Resilience pattern that temporarily disables a frequently-failing tool |
| **Panelist Profile** | A predefined expert persona with name, expertise area, personality, icon, and color |
| **Preset Panel** | A pre-configured combination of panelists (e.g., QuickPanel, BalancedPanel) |
| **Follow-Up Q&A** | The ability to ask the Head Agent additional questions after synthesis, with full debate context retained |
| **Three-Pane Layout** | The UI layout: Left (Head Chat), Center (Discussion Stream), Right (Agent Inspector) |
| **Execution Bar** | The pulsing status strip below the header showing real-time execution status, discussion mode badge, active agent, and parallel indicator |
| **Side Panel** | Fly-in settings panel with model selection, configuration, and event log |
| **Phase** | A discrete stage in the discussion lifecycle (Idle, Clarifying, Running, Synthesizing, etc.) |
| **Turn** | One panelist's contribution to the discussion (a single message in the debate) |
| **Agent Inspector** | The right pane that shows per-agent details: status, message count, tool calls, last message |

---

## 22. Frequently Asked Questions

**Q: How many panelists should I use?**
A: For most topics, 4â€“5 is optimal. Three feels thin; more than 6 can be noisy without proportional insight gain. Start with the BalancedPanel preset (5) and adjust from there.

**Q: Does the panel remember previous discussions?**
A: No. Each panel discussion is independent. Reset clears all context. If you need continuity, reference previous findings in your new topic description.

**Q: Can I change panelists mid-discussion?**
A: Not during a running discussion. You'd need to Stop or Reset and start a new discussion with different panelist preferences.

**Q: What happens if I reject the plan?**
A: The Head Agent receives your rejection and any feedback you type. It revises the plan and presents a new one for approval. You can reject as many times as needed.

**Q: Can panelists use tools (file reading, web search, etc.)?**
A: Yes, if enabled in settings. All 8 default profiles have tools enabled. The Guard Rail Policy limits tool calls per turn (5) and per discussion (50) to prevent abuse.

**Q: How is cost calculated?**
A: The ðŸ’° badge shows an estimate based on token usage across all agents. Actual cost depends on your Copilot plan. A typical Standard-depth discussion with 5 panelists costs roughly the equivalent of 15â€“30 individual chat messages.

**Q: Can I use Panel Discussion for code review?**
A: Absolutely. Paste the code or reference a file path in your topic. Enable file system access so panelists can read the actual code. Example: "Review the authentication middleware in `src/middleware/auth.ts` â€” focus on security, error handling, and testability."

**Q: Why does the Head Agent sometimes skip clarification?**
A: If your topic is specific enough, the Head determines that clarification is unnecessary and proceeds directly to planning. This is intentional and saves time.

**Q: What's the difference between Pause and Stop?**
A: **Pause** freezes the discussion â€” you can Resume to continue from where you left off. **Stop** terminates the discussion permanently â€” to continue, you must Reset and start over.

**Q: Can I send messages to the Head during the discussion?**
A: Yes. Use the input bar to send messages while the discussion is Running. The Head Agent processes your message and may adjust the discussion direction.

**Q: Why would I set Commentary Mode to Detailed?**
A: To understand the Moderator's reasoning â€” useful when debugging why convergence isn't rising, or when learning how the system works. For everyday use, Brief is sufficient.

**Q: What if I want more than 8 panelists?**
A: The default Max Panelists setting caps at 8 (matching the 8 built-in profiles). In practice, 5â€“6 is the sweet spot for quality vs. cost.

**Q: Can I use different models for different panelists?**
A: Yes. The Panelist Model Pool supports multi-select. Each panelist is randomly assigned from the selected pool. This lets you mix premium and economy models.

---

## 23. Appendix â€” Keyboard Shortcuts

| Shortcut | Context | Action |
|---|---|---|
| **Enter** | Input focused, no Shift | Send message / start panel |
| **Shift+Enter** | Input focused | New line (multi-line input) |
| **Escape** | Side panel open | Close side panel |
| **Escape** | Synthesis overlay open | Dismiss synthesis |

---

<p align="center">
  <em>CopilotDesktop Panel Discussion â€” Assemble the experts. Debate the hard questions. Ship with confidence.</em><br/>
  <strong>Â© 2026 CopilotDesktop. All rights reserved.</strong>
</p>